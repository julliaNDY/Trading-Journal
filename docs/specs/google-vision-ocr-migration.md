# üìã Sp√©cifications Techniques : Migration OCR vers Google Cloud Vision API

> **Document** : PRD-OCR-VISION-001  
> **Version** : 1.0  
> **Date** : 2026-01-08  
> **Auteur** : John (PM)  
> **Status** : Draft - En attente de validation

---

## üìë Table des mati√®res

1. [R√©sum√© Ex√©cutif](#1-r√©sum√©-ex√©cutif)
2. [Analyse de l'Existant](#2-analyse-de-lexistant)
3. [Architecture & Flux de Donn√©es](#3-architecture--flux-de-donn√©es)
4. [User Stories & T√¢ches Techniques](#4-user-stories--t√¢ches-techniques)
5. [Gestion des Erreurs & Edge Cases](#5-gestion-des-erreurs--edge-cases)
6. [Plan d'Impl√©mentation](#6-plan-dimpl√©mentation)
7. [Tests & Validation](#7-tests--validation)
8. [Annexes](#8-annexes)

---

## 1. R√©sum√© Ex√©cutif

### 1.1 Contexte

Le module OCR actuel utilise **Tesseract.js** pour extraire les donn√©es de trades depuis des captures d'√©cran. Cette solution pr√©sente plusieurs limitations :

| Probl√®me | Impact |
|----------|--------|
| Bundle client ~7MB | Performance de chargement d√©grad√©e |
| Pr√©cision OCR ~75-85% | Nombreux faux positifs, regex complexes |
| Pas de confidence score | Impossible de filtrer les r√©sultats incertains |
| Preprocessing manuel | 50+ lignes de manipulation canvas |

### 1.2 Solution Propos√©e

Migration vers **Google Cloud Vision API** (Document Text Detection) :

| Avantage | B√©n√©fice |
|----------|----------|
| Pr√©cision ~95%+ | Moins de regex, parsing simplifi√© |
| Confidence scores | Filtrage intelligent des r√©sultats |
| Traitement serveur | Bundle client all√©g√© de 7MB |
| Structure hi√©rarchique | Blocks ‚Üí Paragraphs ‚Üí Words ‚Üí Symbols |
| Support multi-langues | D√©tection automatique FR/EN |

### 1.3 Estimation

| Phase | Dur√©e | Complexit√© |
|-------|-------|------------|
| Configuration GCP | 2h | Faible |
| Service Backend OCR | 4h | Moyenne |
| Refonte Parsing | 6h | Haute |
| Migration Frontend | 3h | Moyenne |
| Tests & QA | 3h | Moyenne |
| **Total** | **18h** | - |

---

## 2. Analyse de l'Existant

### 2.1 Architecture Actuelle

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        FRONTEND (Client)                         ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  ocr-import-dialog.tsx                                          ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ Image preprocessing (canvas manipulation)                   ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ Tesseract.recognize() ~7MB WASM                            ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ parseOcrText() ‚Üí OcrTradeData[]                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    ocr-service.ts (Shared)                       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  ‚Ä¢ findDateTimes()      - Regex patterns date/time              ‚îÇ
‚îÇ  ‚Ä¢ extractPrices()      - Regex avec correction erreurs OCR     ‚îÇ
‚îÇ  ‚Ä¢ extractPnL()         - Regex multi-formats ($, ‚Ç¨, etc.)      ‚îÇ
‚îÇ  ‚Ä¢ extractQuantity()    - Regex +1, -2, etc.                    ‚îÇ
‚îÇ  ‚Ä¢ extractDrawdownRunup() - Regex MAE/MFE                       ‚îÇ
‚îÇ  ‚Ä¢ parseOcrText()       - Orchestration parsing                 ‚îÇ
‚îÇ  ‚Ä¢ consolidateRawRows() - Groupement partial exits              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 2.2 Fichiers Impact√©s

| Fichier | Lignes | Action |
|---------|--------|--------|
| `src/components/import/ocr-import-dialog.tsx` | 505 | **Modifier** - Supprimer Tesseract, appeler API |
| `src/services/ocr-service.ts` | 600 | **Modifier** - Adapter parsing pour Vision API |
| `src/app/api/ocr/parse/route.ts` | 75 | **Remplacer** - Int√©grer Vision API |
| `src/lib/google-vision.ts` | - | **Cr√©er** - Client Vision API |
| `src/types/google-vision.d.ts` | - | **Cr√©er** - Types TypeScript |

### 2.3 D√©pendances √† Modifier

```json
// √Ä SUPPRIMER de package.json
"tesseract.js": "^5.x.x"

// √Ä AJOUTER
"@google-cloud/vision": "^4.x.x"
```

---

## 3. Architecture & Flux de Donn√©es

### 3.1 Nouvelle Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        FRONTEND (Client)                         ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  ocr-import-dialog.tsx                                          ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ FileReader ‚Üí Base64                                        ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ POST /api/ocr/parse { image: base64, symbol?: string }     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ Display OcrParseResult                                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    API Route (Server)                            ‚îÇ
‚îÇ                 /api/ocr/parse/route.ts                          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  1. Authenticate user (Supabase)                                ‚îÇ
‚îÇ  2. Validate image (size, format)                               ‚îÇ
‚îÇ  3. Call Google Vision API                                      ‚îÇ
‚îÇ  4. Parse structured response                                   ‚îÇ
‚îÇ  5. Return OcrParseResult                                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  Google Cloud Vision API                         ‚îÇ
‚îÇ              DOCUMENT_TEXT_DETECTION                             ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Input:  { image: { content: base64 } }                         ‚îÇ
‚îÇ  Output: { fullTextAnnotation: { pages: [...], text: string } } ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    ocr-service.ts (Server)                       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  ‚Ä¢ parseVisionResponse() - Traite structure Vision API          ‚îÇ
‚îÇ  ‚Ä¢ extractTradesFromBlocks() - Nouveau parser optimis√©          ‚îÇ
‚îÇ  ‚Ä¢ (conserve) parseOcrText() - Fallback/compatibilit√©           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 3.2 M√©thode d'Envoi de l'Image

**D√©cision : Base64 (pas URL)**

| Crit√®re | Base64 | URL Sign√©e |
|---------|--------|------------|
| Latence | ‚úÖ Direct | ‚ùå Upload ‚Üí Sign ‚Üí Fetch |
| Complexit√© | ‚úÖ Simple | ‚ùå N√©cessite Storage |
| Co√ªt | ‚úÖ Gratuit | ‚ùå Stockage + Transfer |
| S√©curit√© | ‚úÖ Pas d'URL expos√©e | ‚ö†Ô∏è URL temporaire |
| Limite taille | ‚ö†Ô∏è 10MB max | ‚úÖ Pas de limite |

**Justification** : Les captures d'√©cran de trading font g√©n√©ralement 100KB-2MB. La limite de 10MB de Vision API en Base64 est largement suffisante.

### 3.3 Gestion des Credentials

#### Option A : Service Account Key (Recommand√© pour VPS)

```bash
# .env
GOOGLE_APPLICATION_CREDENTIALS="/path/to/service-account.json"
```

```typescript
// src/lib/google-vision.ts
import { ImageAnnotatorClient } from '@google-cloud/vision';

// Le client utilise automatiquement GOOGLE_APPLICATION_CREDENTIALS
const client = new ImageAnnotatorClient();
```

#### Option B : API Key (Alternative simplifi√©e)

```bash
# .env
GOOGLE_VISION_API_KEY="AIza..."
```

```typescript
// Appel REST direct
const response = await fetch(
  `https://vision.googleapis.com/v1/images:annotate?key=${process.env.GOOGLE_VISION_API_KEY}`,
  {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      requests: [{
        image: { content: base64Image },
        features: [{ type: 'DOCUMENT_TEXT_DETECTION' }],
      }],
    }),
  }
);
```

**Recommandation** : Service Account pour production (meilleure s√©curit√©, quotas par projet), API Key pour d√©veloppement rapide.

### 3.4 Structure de la R√©ponse Google Vision

```typescript
// Types simplifi√©s - voir Annexe A pour types complets
interface VisionResponse {
  fullTextAnnotation: {
    text: string;  // Texte complet d√©tect√©
    pages: VisionPage[];
  };
  textAnnotations?: VisionTextAnnotation[];  // Legacy format
}

interface VisionPage {
  blocks: VisionBlock[];
  confidence: number;
  width: number;
  height: number;
}

interface VisionBlock {
  blockType: 'TEXT' | 'TABLE' | 'PICTURE' | 'RULER' | 'BARCODE';
  paragraphs: VisionParagraph[];
  confidence: number;
  boundingBox: BoundingPoly;
}

interface VisionParagraph {
  words: VisionWord[];
  confidence: number;
  boundingBox: BoundingPoly;
}

interface VisionWord {
  symbols: VisionSymbol[];
  confidence: number;
  boundingBox: BoundingPoly;
  // Texte reconstitu√©
  text: string;  // Nous ajouterons cette propri√©t√© calcul√©e
}

interface VisionSymbol {
  text: string;
  confidence: number;
  boundingBox: BoundingPoly;
  property?: {
    detectedBreak?: {
      type: 'SPACE' | 'SURE_SPACE' | 'EOL_SURE_SPACE' | 'HYPHEN' | 'LINE_BREAK';
    };
  };
}
```

### 3.5 Strat√©gie de Parsing

**Approche hybride** : Utiliser la structure hi√©rarchique quand disponible, fallback sur le texte brut.

```typescript
// src/services/ocr-service.ts (nouvelle fonction)

export function parseVisionResponse(
  response: VisionResponse, 
  symbol?: string
): OcrParseResult {
  // 1. Extraire le texte brut (toujours disponible)
  const rawText = response.fullTextAnnotation?.text || '';
  
  // 2. Si structure disponible, parser par lignes avec confidence
  if (response.fullTextAnnotation?.pages?.length > 0) {
    return parseStructuredVisionData(response.fullTextAnnotation, symbol);
  }
  
  // 3. Fallback sur le parsing texte existant
  return parseOcrText(rawText, symbol);
}

function parseStructuredVisionData(
  fullText: FullTextAnnotation,
  symbol?: string
): OcrParseResult {
  const lines: ParsedLine[] = [];
  
  for (const page of fullText.pages) {
    for (const block of page.blocks) {
      if (block.blockType !== 'TEXT') continue;
      if (block.confidence < 0.7) continue; // Filtre basse confiance
      
      for (const paragraph of block.paragraphs) {
        const lineText = extractLineText(paragraph);
        const lineConfidence = paragraph.confidence;
        
        lines.push({
          text: lineText,
          confidence: lineConfidence,
          words: paragraph.words.map(w => ({
            text: getWordText(w),
            confidence: w.confidence,
            bounds: w.boundingBox,
          })),
        });
      }
    }
  }
  
  // Parser les lignes avec le contexte de confiance
  return parseLinesToTrades(lines, symbol);
}
```

---

## 4. User Stories & T√¢ches Techniques

### 4.1 Epic : Migration OCR vers Google Cloud Vision

---

#### Story 4.1.1 : Configuration Projet GCP

**En tant que** d√©veloppeur  
**Je veux** configurer un projet Google Cloud avec Vision API  
**Afin de** pouvoir utiliser l'API de d√©tection de texte

**Crit√®res d'Acceptation :**

- [ ] Projet GCP cr√©√© avec nom explicite (`trading-journal-ocr`)
- [ ] Vision API activ√©e dans le projet
- [ ] Service Account cr√©√© avec r√¥le `Cloud Vision API User`
- [ ] Cl√© JSON g√©n√©r√©e et stock√©e s√©curis√©ment
- [ ] Variable `GOOGLE_APPLICATION_CREDENTIALS` document√©e
- [ ] Quota alerting configur√© (1000 requ√™tes/mois gratuit)

**T√¢ches :**

| # | T√¢che | Estimation |
|---|-------|------------|
| 1 | Cr√©er projet GCP via Console | 10min |
| 2 | Activer Cloud Vision API | 5min |
| 3 | Cr√©er Service Account | 10min |
| 4 | G√©n√©rer et t√©l√©charger cl√© JSON | 5min |
| 5 | Ajouter au `.gitignore` | 2min |
| 6 | Documenter dans `env.example` | 5min |
| 7 | Configurer alertes quota | 10min |

---

#### Story 4.1.2 : Client Google Vision (Backend)

**En tant que** d√©veloppeur backend  
**Je veux** un client Vision API r√©utilisable  
**Afin de** centraliser la configuration et la gestion d'erreurs

**Crit√®res d'Acceptation :**

- [ ] Module `src/lib/google-vision.ts` cr√©√©
- [ ] Client singleton avec lazy initialization
- [ ] M√©thode `detectText(imageBase64: string): Promise<VisionResponse>`
- [ ] Gestion timeout configurable (default 30s)
- [ ] Retry automatique (1 retry sur 5xx)
- [ ] Types TypeScript complets
- [ ] Logging structur√© (pas de console.log)

**T√¢ches :**

| # | T√¢che | Fichier | Estimation |
|---|-------|---------|------------|
| 1 | Installer `@google-cloud/vision` | `package.json` | 5min |
| 2 | Cr√©er types Vision API | `src/types/google-vision.d.ts` | 30min |
| 3 | Impl√©menter client singleton | `src/lib/google-vision.ts` | 45min |
| 4 | Ajouter retry logic | `src/lib/google-vision.ts` | 20min |
| 5 | Tests unitaires | `src/lib/__tests__/google-vision.test.ts` | 30min |

**Code Cible :**

```typescript
// src/lib/google-vision.ts
import { ImageAnnotatorClient } from '@google-cloud/vision';
import type { google } from '@google-cloud/vision/build/protos/protos';

type VisionResponse = google.cloud.vision.v1.IAnnotateImageResponse;

class GoogleVisionClient {
  private client: ImageAnnotatorClient | null = null;
  private readonly maxRetries = 1;
  private readonly timeout = 30000; // 30s

  private getClient(): ImageAnnotatorClient {
    if (!this.client) {
      this.client = new ImageAnnotatorClient();
    }
    return this.client;
  }

  async detectText(imageBase64: string): Promise<VisionResponse> {
    const client = this.getClient();
    
    const request = {
      image: { content: imageBase64 },
      features: [{ type: 'DOCUMENT_TEXT_DETECTION' as const }],
    };

    let lastError: Error | null = null;
    
    for (let attempt = 0; attempt <= this.maxRetries; attempt++) {
      try {
        const [result] = await Promise.race([
          client.annotateImage(request),
          this.createTimeout(),
        ]);
        
        if (result.error) {
          throw new Error(`Vision API error: ${result.error.message}`);
        }
        
        return result;
      } catch (error) {
        lastError = error as Error;
        
        // Ne retry que sur erreurs serveur
        if (!this.isRetryable(error)) {
          throw error;
        }
        
        // Attendre avant retry (exponential backoff)
        await this.sleep(1000 * (attempt + 1));
      }
    }
    
    throw lastError;
  }

  private createTimeout(): Promise<never> {
    return new Promise((_, reject) => {
      setTimeout(() => reject(new Error('Vision API timeout')), this.timeout);
    });
  }

  private isRetryable(error: unknown): boolean {
    if (error instanceof Error) {
      // Retry sur erreurs 5xx ou r√©seau
      return error.message.includes('5') || 
             error.message.includes('UNAVAILABLE') ||
             error.message.includes('DEADLINE_EXCEEDED');
    }
    return false;
  }

  private sleep(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms));
  }
}

// Singleton export
export const visionClient = new GoogleVisionClient();
```

---

#### Story 4.1.3 : Refonte API Route OCR

**En tant que** d√©veloppeur backend  
**Je veux** modifier `/api/ocr/parse` pour utiliser Google Vision  
**Afin de** am√©liorer la pr√©cision de d√©tection

**Crit√®res d'Acceptation :**

- [ ] Route accepte `{ image: string (base64), symbol?: string }`
- [ ] Validation taille image (max 10MB)
- [ ] Validation format (JPEG, PNG, WebP, GIF)
- [ ] Appel Google Vision via client centralis√©
- [ ] Parsing via `parseVisionResponse()`
- [ ] Retour `OcrParseResult` compatible avec l'existant
- [ ] Gestion erreurs avec codes appropri√©s (400, 401, 413, 500, 503)

**T√¢ches :**

| # | T√¢che | Estimation |
|---|-------|------------|
| 1 | Supprimer import Tesseract | 5min |
| 2 | Ajouter validation image | 20min |
| 3 | Int√©grer visionClient | 15min |
| 4 | Adapter response parsing | 30min |
| 5 | Tests d'int√©gration | 45min |

**Code Cible :**

```typescript
// src/app/api/ocr/parse/route.ts
import { NextRequest, NextResponse } from 'next/server';
import { createClient } from '@/lib/supabase/server';
import { visionClient } from '@/lib/google-vision';
import { parseVisionResponse } from '@/services/ocr-service';

export const runtime = 'nodejs';
export const maxDuration = 60;

const MAX_IMAGE_SIZE = 10 * 1024 * 1024; // 10MB
const ALLOWED_TYPES = ['image/jpeg', 'image/png', 'image/webp', 'image/gif'];

interface OcrRequestBody {
  image: string;  // Base64
  symbol?: string;
}

export async function POST(request: NextRequest) {
  try {
    // 1. Auth
    const supabase = await createClient();
    const { data: { user }, error: authError } = await supabase.auth.getUser();
    
    if (authError || !user) {
      return NextResponse.json({ error: 'Unauthorized' }, { status: 401 });
    }

    // 2. Parse body
    const body: OcrRequestBody = await request.json();
    
    if (!body.image) {
      return NextResponse.json({ error: 'Image is required' }, { status: 400 });
    }

    // 3. Validate image
    const imageBuffer = Buffer.from(body.image, 'base64');
    
    if (imageBuffer.length > MAX_IMAGE_SIZE) {
      return NextResponse.json(
        { error: 'Image too large', maxSize: '10MB' }, 
        { status: 413 }
      );
    }

    // Detect MIME type from magic bytes
    const mimeType = detectMimeType(imageBuffer);
    if (!ALLOWED_TYPES.includes(mimeType)) {
      return NextResponse.json(
        { error: 'Invalid image format', allowed: ALLOWED_TYPES }, 
        { status: 400 }
      );
    }

    // 4. Call Vision API
    const visionResponse = await visionClient.detectText(body.image);

    // 5. Parse response
    const parseResult = parseVisionResponse(visionResponse, body.symbol);

    return NextResponse.json(parseResult);
    
  } catch (error) {
    console.error('[OCR API Error]', error);
    
    if (error instanceof Error) {
      if (error.message.includes('timeout')) {
        return NextResponse.json(
          { error: 'OCR processing timeout', retryable: true }, 
          { status: 504 }
        );
      }
      if (error.message.includes('quota')) {
        return NextResponse.json(
          { error: 'API quota exceeded', retryable: false }, 
          { status: 429 }
        );
      }
    }
    
    return NextResponse.json(
      { error: 'OCR processing failed' }, 
      { status: 500 }
    );
  }
}

function detectMimeType(buffer: Buffer): string {
  const magicBytes = buffer.subarray(0, 4);
  
  // JPEG: FF D8 FF
  if (magicBytes[0] === 0xFF && magicBytes[1] === 0xD8 && magicBytes[2] === 0xFF) {
    return 'image/jpeg';
  }
  // PNG: 89 50 4E 47
  if (magicBytes[0] === 0x89 && magicBytes[1] === 0x50 && magicBytes[2] === 0x4E && magicBytes[3] === 0x47) {
    return 'image/png';
  }
  // GIF: 47 49 46 38
  if (magicBytes[0] === 0x47 && magicBytes[1] === 0x49 && magicBytes[2] === 0x46) {
    return 'image/gif';
  }
  // WebP: 52 49 46 46 ... 57 45 42 50
  if (magicBytes[0] === 0x52 && magicBytes[1] === 0x49 && magicBytes[2] === 0x46 && magicBytes[3] === 0x46) {
    return 'image/webp';
  }
  
  return 'application/octet-stream';
}
```

---

#### Story 4.1.4 : Nouveau Parser Vision API

**En tant que** d√©veloppeur backend  
**Je veux** un parser optimis√© pour les r√©ponses Google Vision  
**Afin de** exploiter la structure hi√©rarchique et les scores de confiance

**Crit√®res d'Acceptation :**

- [ ] Fonction `parseVisionResponse()` cr√©√©e
- [ ] Exploitation de la structure blocks/paragraphs/words
- [ ] Filtrage par confidence score (seuil configurable, default 0.7)
- [ ] Fallback sur `parseOcrText()` si structure absente
- [ ] Compatibilit√© totale avec `OcrParseResult` existant
- [ ] Tests unitaires avec snapshots de r√©ponses Vision API

**T√¢ches :**

| # | T√¢che | Estimation |
|---|-------|------------|
| 1 | Cr√©er `parseVisionResponse()` | 1h |
| 2 | Impl√©menter `extractLineText()` helper | 30min |
| 3 | Adapter `parseLinesToTrades()` | 1h |
| 4 | Ajouter confidence filtering | 20min |
| 5 | Tests avec mocks Vision | 1h |

**Code Cible :**

```typescript
// Ajout √† src/services/ocr-service.ts

import type { google } from '@google-cloud/vision/build/protos/protos';

type FullTextAnnotation = google.cloud.vision.v1.ITextAnnotation;
type Block = google.cloud.vision.v1.IBlock;
type Paragraph = google.cloud.vision.v1.IParagraph;
type Word = google.cloud.vision.v1.IWord;
type Symbol = google.cloud.vision.v1.ISymbol;

const DEFAULT_CONFIDENCE_THRESHOLD = 0.7;

export interface VisionParseOptions {
  confidenceThreshold?: number;
  symbol?: string;
}

export function parseVisionResponse(
  response: google.cloud.vision.v1.IAnnotateImageResponse,
  options: VisionParseOptions = {}
): OcrParseResult {
  const { 
    confidenceThreshold = DEFAULT_CONFIDENCE_THRESHOLD,
    symbol 
  } = options;

  const fullText = response.fullTextAnnotation;
  
  // Si pas de structure, fallback sur le texte brut
  if (!fullText?.pages?.length) {
    const rawText = fullText?.text || '';
    return parseOcrText(rawText, symbol);
  }

  const warnings: string[] = [];
  const lines: string[] = [];
  let lowConfidenceCount = 0;

  // Extraire les lignes depuis la structure
  for (const page of fullText.pages) {
    for (const block of page.blocks || []) {
      // Skip blocs non-texte
      if (block.blockType !== 'TEXT') continue;
      
      for (const paragraph of block.paragraphs || []) {
        const confidence = paragraph.confidence ?? 1;
        
        if (confidence < confidenceThreshold) {
          lowConfidenceCount++;
          continue;
        }

        const lineText = extractParagraphText(paragraph);
        if (lineText.trim()) {
          lines.push(lineText);
        }
      }
    }
  }

  if (lowConfidenceCount > 0) {
    warnings.push(`${lowConfidenceCount} paragraphe(s) ignor√©(s) (confiance < ${confidenceThreshold * 100}%)`);
  }

  // Reconstituer le texte et parser
  const reconstructedText = lines.join('\n');
  const result = parseOcrText(reconstructedText, symbol);

  return {
    ...result,
    rawText: fullText.text || reconstructedText,
    warnings: [...result.warnings, ...warnings],
  };
}

/**
 * Extrait le texte d'un paragraphe en reconstituant les espaces
 */
function extractParagraphText(paragraph: Paragraph): string {
  const parts: string[] = [];

  for (const word of paragraph.words || []) {
    let wordText = '';
    
    for (const symbol of word.symbols || []) {
      wordText += symbol.text || '';
      
      // Ajouter espace/newline selon le break type
      const breakType = symbol.property?.detectedBreak?.type;
      if (breakType === 'SPACE' || breakType === 'SURE_SPACE') {
        wordText += ' ';
      } else if (breakType === 'EOL_SURE_SPACE' || breakType === 'LINE_BREAK') {
        wordText += '\n';
      }
    }
    
    parts.push(wordText);
  }

  return parts.join('').trim();
}

/**
 * Calcule le texte d'un mot (helper)
 */
function getWordText(word: Word): string {
  return (word.symbols || []).map(s => s.text || '').join('');
}
```

---

#### Story 4.1.5 : Refonte Frontend OCR Dialog

**En tant que** utilisateur  
**Je veux** que l'import OCR soit plus rapide et fiable  
**Afin de** r√©duire les erreurs de reconnaissance

**Crit√®res d'Acceptation :**

- [ ] Tesseract.js supprim√© du composant
- [ ] Image convertie en Base64 c√¥t√© client
- [ ] Appel API `POST /api/ocr/parse` avec body JSON
- [ ] Loader am√©lior√© avec message de progression
- [ ] Gestion erreurs r√©seau avec retry manuel
- [ ] Pr√©servation de toute l'UX existante (preview, symbol input, etc.)

**T√¢ches :**

| # | T√¢che | Estimation |
|---|-------|------------|
| 1 | Supprimer import Tesseract | 5min |
| 2 | Cr√©er fonction `imageToBase64()` | 15min |
| 3 | Remplacer `handleFileChange()` | 30min |
| 4 | Adapter √©tats de chargement | 20min |
| 5 | Am√©liorer messages d'erreur | 15min |
| 6 | Tester sur diff√©rents navigateurs | 30min |

**Code Cible :**

```typescript
// src/components/import/ocr-import-dialog.tsx (extrait)

// SUPPRIMER: import Tesseract from 'tesseract.js';

// AJOUTER:
async function imageToBase64(file: File): Promise<string> {
  return new Promise((resolve, reject) => {
    const reader = new FileReader();
    reader.onload = () => {
      const result = reader.result as string;
      // Extraire la partie base64 (retirer le pr√©fixe data:image/xxx;base64,)
      const base64 = result.split(',')[1];
      resolve(base64);
    };
    reader.onerror = reject;
    reader.readAsDataURL(file);
  });
}

// MODIFIER handleFileChange:
const handleFileChange = async (e: React.ChangeEvent<HTMLInputElement>) => {
  const file = e.target.files?.[0];
  if (!file) return;

  // Validation c√¥t√© client
  const maxSize = 10 * 1024 * 1024; // 10MB
  if (file.size > maxSize) {
    toast({
      title: tCommon('error'),
      description: tTrades('imageTooLarge'),
      variant: 'destructive',
    });
    e.target.value = '';
    return;
  }

  setIsProcessingOcr(true);
  setOcrProgress('converting'); // Nouveau √©tat

  try {
    // 1. Convertir en Base64
    const base64Image = await imageToBase64(file);
    
    setOcrProgress('analyzing'); // Nouveau √©tat

    // 2. Appeler l'API
    const response = await fetch('/api/ocr/parse', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        image: base64Image,
        symbol: symbol || undefined,
      }),
    });

    if (!response.ok) {
      const error = await response.json();
      throw new Error(error.error || 'OCR failed');
    }

    const result: OcrParseResult = await response.json();
    
    setRawOcrText(result.rawText);
    
    if (result.trades.length > 0) {
      setParsedTrades(result.trades);
      onOpenChange(false);
      setShowConfirmDialog(true);
    } else if (result.rawText.trim()) {
      // Texte d√©tect√© mais pas de trades pars√©s
      onOpenChange(false);
      setShowConfirmDialog(true);
      toast({
        title: tCommon('info'),
        description: tTrades('enterSymbolToReparse'),
      });
    } else {
      toast({
        title: tCommon('info'),
        description: tTrades('ocrNoMatches'),
      });
    }

    // Afficher les warnings √©ventuels
    if (result.warnings.length > 0) {
      console.warn('OCR warnings:', result.warnings);
    }

  } catch (error) {
    console.error('OCR error:', error);
    
    let description = tTrades('ocrError');
    if (error instanceof Error) {
      if (error.message.includes('timeout')) {
        description = tTrades('ocrTimeout');
      } else if (error.message.includes('quota')) {
        description = tTrades('ocrQuotaExceeded');
      }
    }
    
    toast({
      title: tCommon('error'),
      description,
      variant: 'destructive',
    });
  } finally {
    setIsProcessingOcr(false);
    setOcrProgress(null);
    e.target.value = '';
  }
};
```

---

#### Story 4.1.6 : Nettoyage & Suppression Tesseract

**En tant que** d√©veloppeur  
**Je veux** supprimer Tesseract.js du projet  
**Afin de** r√©duire la taille du bundle client de ~7MB

**Crit√®res d'Acceptation :**

- [ ] `tesseract.js` supprim√© de `package.json`
- [ ] Aucun import Tesseract restant dans le code
- [ ] Bundle size v√©rifi√© (diff avant/apr√®s)
- [ ] Build r√©ussi sans erreurs

**T√¢ches :**

| # | T√¢che | Estimation |
|---|-------|------------|
| 1 | `npm uninstall tesseract.js` | 2min |
| 2 | Grep tous les imports Tesseract | 5min |
| 3 | Supprimer imports r√©siduels | 10min |
| 4 | V√©rifier build | 5min |
| 5 | Comparer bundle size | 10min |

---

### 4.2 R√©capitulatif Stories

| # | Story | Estimation | Priorit√© | D√©pendances |
|---|-------|------------|----------|-------------|
| 4.1.1 | Configuration GCP | 45min | P0 | - |
| 4.1.2 | Client Vision Backend | 2h | P0 | 4.1.1 |
| 4.1.3 | Refonte API Route | 2h | P0 | 4.1.2 |
| 4.1.4 | Nouveau Parser | 3h | P0 | 4.1.2 |
| 4.1.5 | Refonte Frontend | 2h | P0 | 4.1.3 |
| 4.1.6 | Cleanup Tesseract | 30min | P1 | 4.1.5 |

**Chemin critique** : 4.1.1 ‚Üí 4.1.2 ‚Üí 4.1.3/4.1.4 (parall√®le) ‚Üí 4.1.5 ‚Üí 4.1.6

---

## 5. Gestion des Erreurs & Edge Cases

### 5.1 Matrice des Erreurs

| Sc√©nario | D√©tection | R√©ponse API | Action UI |
|----------|-----------|-------------|-----------|
| Image floue | `confidence < 0.5` sur >50% des blocs | `{ trades: [], warnings: ["Low quality image"] }` | Toast warning + suggestion re-upload |
| Image trop grande | `buffer.length > 10MB` | `413 { error: "Image too large" }` | Toast error + limite affich√©e |
| Format invalide | Magic bytes check | `400 { error: "Invalid format" }` | Toast error + formats accept√©s |
| Timeout Vision API | `DEADLINE_EXCEEDED` | `504 { error: "Timeout", retryable: true }` | Toast + bouton "R√©essayer" |
| Quota d√©pass√© | `RESOURCE_EXHAUSTED` | `429 { error: "Quota exceeded" }` | Toast error + contact admin |
| Erreur r√©seau | `fetch` throws | N/A | Toast + bouton "R√©essayer" |
| Pas de texte d√©tect√© | `fullTextAnnotation.text === ''` | `{ trades: [], rawText: '' }` | Toast info "Aucun texte d√©tect√©" |
| Texte d√©tect√©, pas de trades | Trades array vide | `{ trades: [], rawText: "..." }` | Dialog avec input symbole |

### 5.2 Gestion Image Floue

```typescript
// src/services/ocr-service.ts

export function analyzeImageQuality(
  response: VisionResponse
): { quality: 'good' | 'medium' | 'poor'; avgConfidence: number } {
  const confidences: number[] = [];
  
  for (const page of response.fullTextAnnotation?.pages || []) {
    for (const block of page.blocks || []) {
      if (block.confidence !== undefined) {
        confidences.push(block.confidence);
      }
    }
  }
  
  if (confidences.length === 0) {
    return { quality: 'poor', avgConfidence: 0 };
  }
  
  const avg = confidences.reduce((a, b) => a + b, 0) / confidences.length;
  
  return {
    quality: avg >= 0.85 ? 'good' : avg >= 0.7 ? 'medium' : 'poor',
    avgConfidence: avg,
  };
}
```

### 5.3 Retry Strategy

```typescript
// src/components/import/ocr-import-dialog.tsx

const [retryCount, setRetryCount] = useState(0);
const MAX_RETRIES = 2;

const handleRetry = async () => {
  if (retryCount >= MAX_RETRIES) {
    toast({
      title: tCommon('error'),
      description: tTrades('maxRetriesReached'),
      variant: 'destructive',
    });
    return;
  }
  
  setRetryCount(prev => prev + 1);
  // Re-trigger avec la derni√®re image
  if (lastImageBase64) {
    await processImage(lastImageBase64);
  }
};
```

### 5.4 Quotas API

**Google Cloud Vision - Free Tier :**
- 1000 requ√™tes/mois gratuites
- $1.50 pour 1000 requ√™tes suppl√©mentaires

**Monitoring recommand√© :**

```typescript
// src/lib/google-vision.ts

let requestCount = 0;
const QUOTA_WARNING_THRESHOLD = 800; // 80% du quota gratuit

export function getQuotaStatus(): { count: number; warning: boolean } {
  return {
    count: requestCount,
    warning: requestCount >= QUOTA_WARNING_THRESHOLD,
  };
}

// Dans detectText():
requestCount++;
if (requestCount === QUOTA_WARNING_THRESHOLD) {
  console.warn('[Vision API] Approaching quota limit');
  // TODO: Envoyer alerte admin
}
```

---

## 6. Plan d'Impl√©mentation

### 6.1 Ordre des Op√©rations

```
Phase 1: Setup (sans casser l'existant)
‚îú‚îÄ‚îÄ 1. Configurer projet GCP et credentials
‚îú‚îÄ‚îÄ 2. Installer @google-cloud/vision
‚îú‚îÄ‚îÄ 3. Cr√©er src/lib/google-vision.ts
‚îú‚îÄ‚îÄ 4. Cr√©er src/types/google-vision.d.ts
‚îî‚îÄ‚îÄ 5. Ajouter variables env (GOOGLE_APPLICATION_CREDENTIALS)

Phase 2: Backend (route alternative)
‚îú‚îÄ‚îÄ 6. Cr√©er src/app/api/ocr/vision/route.ts (nouvelle route)
‚îú‚îÄ‚îÄ 7. Ajouter parseVisionResponse() √† ocr-service.ts
‚îú‚îÄ‚îÄ 8. Tests unitaires backend
‚îî‚îÄ‚îÄ 9. Tests d'int√©gration avec vraies images

Phase 3: Frontend (feature flag)
‚îú‚îÄ‚îÄ 10. Ajouter feature flag USE_VISION_API
‚îú‚îÄ‚îÄ 11. Cr√©er fonction imageToBase64()
‚îú‚îÄ‚îÄ 12. Modifier handleFileChange() avec condition
‚îú‚îÄ‚îÄ 13. Tester en parall√®le (Tesseract vs Vision)
‚îî‚îÄ‚îÄ 14. Comparer r√©sultats et ajuster parsing

Phase 4: Migration compl√®te
‚îú‚îÄ‚îÄ 15. Activer Vision API par d√©faut
‚îú‚îÄ‚îÄ 16. Supprimer code Tesseract
‚îú‚îÄ‚îÄ 17. Renommer route /api/ocr/vision ‚Üí /api/ocr/parse
‚îú‚îÄ‚îÄ 18. npm uninstall tesseract.js
‚îî‚îÄ‚îÄ 19. D√©ployer et monitorer

Phase 5: Post-migration
‚îú‚îÄ‚îÄ 20. V√©rifier bundle size
‚îú‚îÄ‚îÄ 21. Monitorer quotas API
‚îî‚îÄ‚îÄ 22. Documenter dans PROJECT_MEMORY.md
```

### 6.2 Fichiers √† Cr√©er

| # | Fichier | Description |
|---|---------|-------------|
| 1 | `src/lib/google-vision.ts` | Client Vision API singleton |
| 2 | `src/types/google-vision.d.ts` | Types TypeScript |
| 3 | `src/lib/__tests__/google-vision.test.ts` | Tests unitaires client |
| 4 | `src/app/api/ocr/vision/route.ts` | Route temporaire Vision |
| 5 | `src/services/__tests__/ocr-vision.test.ts` | Tests parser Vision |

### 6.3 Fichiers √† Modifier

| # | Fichier | Modifications |
|---|---------|---------------|
| 1 | `package.json` | +`@google-cloud/vision`, -`tesseract.js` |
| 2 | `env.example` | +`GOOGLE_APPLICATION_CREDENTIALS` |
| 3 | `.gitignore` | +`*.json` credentials |
| 4 | `src/services/ocr-service.ts` | +`parseVisionResponse()` |
| 5 | `src/components/import/ocr-import-dialog.tsx` | Refonte compl√®te |
| 6 | `src/app/api/ocr/parse/route.ts` | Remplacer Tesseract par Vision |
| 7 | `messages/fr.json` | +cl√©s erreurs OCR |
| 8 | `messages/en.json` | +cl√©s erreurs OCR |

### 6.4 Variables d'Environnement

```bash
# Ajout √† .env et env.example

# ===========================================
# GOOGLE CLOUD VISION (pour OCR)
# ===========================================
# Option 1: Service Account JSON file path
# G√©n√©rer depuis: GCP Console > IAM > Service Accounts > Create Key
GOOGLE_APPLICATION_CREDENTIALS="/path/to/service-account.json"

# Option 2: API Key (alternative plus simple)
# G√©n√©rer depuis: GCP Console > APIs & Services > Credentials
# GOOGLE_VISION_API_KEY="AIza..."

# Quota monitoring (optionnel)
# GOOGLE_VISION_QUOTA_ALERT_EMAIL="admin@example.com"
```

---

## 7. Tests & Validation

### 7.1 Tests Unitaires

```typescript
// src/lib/__tests__/google-vision.test.ts

import { describe, it, expect, vi } from 'vitest';
import { visionClient } from '../google-vision';

describe('GoogleVisionClient', () => {
  it('should detect text from base64 image', async () => {
    // Mock the Vision API response
    const mockResponse = {
      fullTextAnnotation: {
        text: '12/30/2025 10:09:48 AM 25717.25 ...',
        pages: [/* ... */],
      },
    };
    
    vi.spyOn(visionClient, 'detectText').mockResolvedValue(mockResponse);
    
    const result = await visionClient.detectText('base64string...');
    
    expect(result.fullTextAnnotation).toBeDefined();
    expect(result.fullTextAnnotation?.text).toContain('12/30/2025');
  });

  it('should handle timeout gracefully', async () => {
    vi.spyOn(visionClient, 'detectText').mockRejectedValue(
      new Error('DEADLINE_EXCEEDED')
    );
    
    await expect(visionClient.detectText('...')).rejects.toThrow('DEADLINE');
  });

  it('should retry on server errors', async () => {
    const detectSpy = vi.spyOn(visionClient, 'detectText');
    
    // Fail first, succeed second
    detectSpy
      .mockRejectedValueOnce(new Error('503 Service Unavailable'))
      .mockResolvedValueOnce({ fullTextAnnotation: { text: 'success' } });
    
    const result = await visionClient.detectText('...');
    
    expect(detectSpy).toHaveBeenCalledTimes(2);
    expect(result.fullTextAnnotation?.text).toBe('success');
  });
});
```

### 7.2 Tests d'Int√©gration

```typescript
// src/services/__tests__/ocr-vision.test.ts

import { describe, it, expect } from 'vitest';
import { parseVisionResponse } from '../ocr-service';
import { sampleVisionResponse } from './__fixtures__/vision-responses';

describe('parseVisionResponse', () => {
  it('should parse structured Vision response', () => {
    const result = parseVisionResponse(sampleVisionResponse, { symbol: 'MNQ' });
    
    expect(result.trades.length).toBeGreaterThan(0);
    expect(result.trades[0]).toMatchObject({
      entryDt: expect.stringMatching(/\d{1,2}\/\d{1,2}\/\d{4}/),
      exitDt: expect.any(String),
      entryPrice: expect.any(Number),
      exitPrice: expect.any(Number),
      profitLoss: expect.any(Number),
    });
  });

  it('should filter low confidence blocks', () => {
    const lowConfidenceResponse = {
      fullTextAnnotation: {
        text: 'some text',
        pages: [{
          blocks: [{
            blockType: 'TEXT',
            confidence: 0.3, // Below threshold
            paragraphs: [{ words: [{ symbols: [{ text: 'x' }] }] }],
          }],
        }],
      },
    };
    
    const result = parseVisionResponse(lowConfidenceResponse);
    
    expect(result.warnings).toContain(expect.stringMatching(/ignor√©/));
  });

  it('should fallback to text parsing when no structure', () => {
    const textOnlyResponse = {
      fullTextAnnotation: {
        text: '12/30/2025 10:09:48 AM 25717.25 25718.00 +50.00$',
        pages: [], // No structured data
      },
    };
    
    const result = parseVisionResponse(textOnlyResponse, { symbol: 'MNQ' });
    
    // Should still parse using the raw text
    expect(result.rawText).toContain('12/30/2025');
  });
});
```

### 7.3 Tests E2E (Manuel)

| # | Sc√©nario | Image Test | R√©sultat Attendu |
|---|----------|------------|------------------|
| 1 | Screenshot NinjaTrader clair | `test-ninjatrader-light.png` | ‚â•90% trades d√©tect√©s |
| 2 | Screenshot Tradovate sombre | `test-tradovate-dark.png` | ‚â•90% trades d√©tect√©s |
| 3 | Image floue (basse r√©solution) | `test-blurry.png` | Warning qualit√© |
| 4 | Image sans texte trading | `test-random-image.png` | 0 trades, message info |
| 5 | Image tr√®s grande (15MB) | `test-large.png` | Erreur 413 |

### 7.4 M√©triques de Validation

| M√©trique | Seuil Minimum | Cible |
|----------|---------------|-------|
| Pr√©cision d√©tection | 85% | 95% |
| Temps de traitement | <10s | <5s |
| Taux d'erreur API | <5% | <1% |
| Bundle size reduction | -5MB | -7MB |

---

## 8. Annexes

### Annexe A : Types Complets Google Vision

```typescript
// src/types/google-vision.d.ts

declare module '@google-cloud/vision' {
  export class ImageAnnotatorClient {
    constructor(options?: ClientOptions);
    annotateImage(request: AnnotateImageRequest): Promise<[AnnotateImageResponse]>;
  }

  interface ClientOptions {
    keyFilename?: string;
    credentials?: Credentials;
    projectId?: string;
  }

  interface Credentials {
    client_email: string;
    private_key: string;
  }

  interface AnnotateImageRequest {
    image: Image;
    features: Feature[];
  }

  interface Image {
    content?: string; // Base64
    source?: ImageSource;
  }

  interface ImageSource {
    imageUri?: string;
    gcsImageUri?: string;
  }

  interface Feature {
    type: 'DOCUMENT_TEXT_DETECTION' | 'TEXT_DETECTION' | 'LABEL_DETECTION';
    maxResults?: number;
  }

  interface AnnotateImageResponse {
    fullTextAnnotation?: TextAnnotation;
    textAnnotations?: EntityAnnotation[];
    error?: Status;
  }

  interface TextAnnotation {
    text: string;
    pages: Page[];
  }

  interface Page {
    property?: TextProperty;
    width: number;
    height: number;
    blocks: Block[];
    confidence: number;
  }

  interface Block {
    property?: TextProperty;
    boundingBox: BoundingPoly;
    paragraphs: Paragraph[];
    blockType: BlockType;
    confidence: number;
  }

  type BlockType = 'UNKNOWN' | 'TEXT' | 'TABLE' | 'PICTURE' | 'RULER' | 'BARCODE';

  interface Paragraph {
    property?: TextProperty;
    boundingBox: BoundingPoly;
    words: Word[];
    confidence: number;
  }

  interface Word {
    property?: TextProperty;
    boundingBox: BoundingPoly;
    symbols: Symbol[];
    confidence: number;
  }

  interface Symbol {
    property?: TextProperty;
    boundingBox: BoundingPoly;
    text: string;
    confidence: number;
  }

  interface TextProperty {
    detectedLanguages?: DetectedLanguage[];
    detectedBreak?: DetectedBreak;
  }

  interface DetectedLanguage {
    languageCode: string;
    confidence: number;
  }

  interface DetectedBreak {
    type: BreakType;
    isPrefix?: boolean;
  }

  type BreakType = 'UNKNOWN' | 'SPACE' | 'SURE_SPACE' | 'EOL_SURE_SPACE' | 'HYPHEN' | 'LINE_BREAK';

  interface BoundingPoly {
    vertices: Vertex[];
    normalizedVertices?: NormalizedVertex[];
  }

  interface Vertex {
    x: number;
    y: number;
  }

  interface NormalizedVertex {
    x: number;
    y: number;
  }

  interface EntityAnnotation {
    mid?: string;
    locale?: string;
    description: string;
    score?: number;
    confidence?: number;
    boundingPoly?: BoundingPoly;
  }

  interface Status {
    code: number;
    message: string;
    details?: any[];
  }
}
```

### Annexe B : Cl√©s i18n √† Ajouter

```json
// messages/fr.json (ajouts)
{
  "trades": {
    "ocrTimeout": "Le traitement de l'image a pris trop de temps. Veuillez r√©essayer.",
    "ocrQuotaExceeded": "Limite de requ√™tes atteinte. Veuillez r√©essayer plus tard.",
    "imageTooLarge": "L'image est trop grande (max 10MB).",
    "imageFormatInvalid": "Format d'image non support√©. Utilisez JPEG, PNG, WebP ou GIF.",
    "ocrLowQuality": "La qualit√© de l'image est faible. Les r√©sultats peuvent √™tre impr√©cis.",
    "ocrRetry": "R√©essayer",
    "maxRetriesReached": "Nombre maximum de tentatives atteint.",
    "ocrAnalyzing": "Analyse en cours...",
    "ocrConverting": "Pr√©paration de l'image..."
  }
}
```

```json
// messages/en.json (ajouts)
{
  "trades": {
    "ocrTimeout": "Image processing took too long. Please try again.",
    "ocrQuotaExceeded": "Request limit reached. Please try again later.",
    "imageTooLarge": "Image is too large (max 10MB).",
    "imageFormatInvalid": "Unsupported image format. Use JPEG, PNG, WebP or GIF.",
    "ocrLowQuality": "Image quality is low. Results may be inaccurate.",
    "ocrRetry": "Retry",
    "maxRetriesReached": "Maximum retry attempts reached.",
    "ocrAnalyzing": "Analyzing...",
    "ocrConverting": "Preparing image..."
  }
}
```

### Annexe C : Checklist de D√©ploiement

```markdown
## Pre-Deployment Checklist

### Configuration GCP
- [ ] Projet GCP cr√©√©
- [ ] Vision API activ√©e
- [ ] Service Account cr√©√© avec r√¥le appropri√©
- [ ] Cl√© JSON g√©n√©r√©e
- [ ] Fichier JSON upload√© sur le serveur (hors repo)
- [ ] `GOOGLE_APPLICATION_CREDENTIALS` configur√© dans .env

### Code
- [ ] Tous les tests passent
- [ ] Build r√©ussi sans erreurs
- [ ] Aucun `console.log` en production
- [ ] Types TypeScript valid√©s

### S√©curit√©
- [ ] Cl√© JSON dans .gitignore
- [ ] Aucune cl√© hardcod√©e dans le code
- [ ] Rate limiting sur l'API route

### Monitoring
- [ ] Alertes quota configur√©es dans GCP
- [ ] Logging structur√© activ√©
- [ ] M√©triques de performance track√©es

### Rollback Plan
- [ ] Branche stable identifi√©e
- [ ] Proc√©dure de rollback document√©e
- [ ] Feature flag disponible pour d√©sactiver Vision API
```

---

## üìù Changelog

| Version | Date | Auteur | Modifications |
|---------|------|--------|---------------|
| 1.0 | 2026-01-08 | John (PM) | Cr√©ation initiale |

---

**Document pr√™t pour validation.**  
Une fois approuv√©, l'impl√©mentation peut commencer par la Story 4.1.1 (Configuration GCP).
