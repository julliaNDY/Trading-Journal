# Story 2.2: Market Data ETL Pipeline - Data Ingestion

## Status

**Draft**

---

## Story

**As a** backend engineer,  
**I want** an ETL pipeline to ingest tick data from market data providers,  
**so that** tick data is stored in TimescaleDB for replay and backtesting.

---

## Acceptance Criteria

1. **AC1**: Service ETL créé dans `src/services/replay/` pour ingérer ticks.
2. **AC2**: Pipeline supporte au moins un provider (Barchart, IBKR, ou Intrinio).
3. **AC3**: Ticks stockés dans TimescaleDB (hypertable `ticks`) avec compression active.
4. **AC4**: Déduplication : pas de ticks dupliqués (unique par timestamp + symbol).
5. **AC5**: Error handling robuste (retry, backoff, logging).
6. **AC6**: Job queue (BullMQ) pour ingestion asynchrone.

---

## Tasks / Subtasks

- [ ] **Task 1: ETL Service Structure** (AC: 1)
  - [ ] 1.1 Créer `src/services/replay/data-ingestion-service.ts`
  - [ ] 1.2 Définir interface `MarketDataProvider` (abstraction multi-provider)
  - [ ] 1.3 Créer types pour tick data (timestamp, symbol, price, volume, etc.)

- [ ] **Task 2: Provider Implementation** (AC: 2)
  - [ ] 2.1 Implémenter provider prioritaire (Barchart/IBKR/Intrinio)
  - [ ] 2.2 Authentication avec provider API
  - [ ] 2.3 Fetch ticks pour période (date range + symbol)
  - [ ] 2.4 Mapping provider format → format interne

- [ ] **Task 3: TimescaleDB Storage** (AC: 3)
  - [ ] 3.1 Vérifier table `ticks` (hypertable) existe (Story 1.1)
  - [ ] 3.2 Implémenter insertion batch dans TimescaleDB
  - [ ] 3.3 Vérifier compression active (policy TimescaleDB)

- [ ] **Task 4: Déduplication** (AC: 4)
  - [ ] 4.1 Vérifier contraintes unique (timestamp + symbol) ou hash
  - [ ] 4.2 Gérer conflits (skip ou update)
  - [ ] 4.3 Tester avec données dupliquées

- [ ] **Task 5: Error Handling** (AC: 5)
  - [ ] 5.1 Retry logic avec exponential backoff
  - [ ] 5.2 Logging structuré (erreurs, stats ingestion)
  - [ ] 5.3 Gestion rate limiting provider

- [ ] **Task 6: Job Queue Integration** (AC: 6)
  - [ ] 6.1 Créer job BullMQ pour ingestion
  - [ ] 6.2 Worker pour exécuter jobs
  - [ ] 6.3 Job parameters (provider, symbol, date range)

---

## Dev Notes

- Dépendance : Story 1.1 (TimescaleDB setup) doit être complétée.
- Dépendance : Story 2.1 (Provider selection) doit être complétée.
- Utiliser abstraction `MarketDataProvider` pour faciliter ajout futurs providers.
- Performance : insertion batch pour optimiser throughput (1000+ ticks par batch).
- Référencer `docs/architecture-trading-path-journal.md` Section 2.3.3 (Data Pipeline).
